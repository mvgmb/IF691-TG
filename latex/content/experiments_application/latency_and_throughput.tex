\subsection{Latency \& Throughput}

These charts represent the \gls{p90} of Latency and Throughput of all 10000 requests made by the persistent and ephemeral clients during the experiments.

Local \gls{http}/1 experiment had the best results overall, with lowest latency and highest throughput, since it fits perfectly with sequential requests. Local \gls{http}/2 was also at the top, only losing to \gls{http}/1 due to the extra features it implements overhead. For instance, \gls{http}/2 always compresses its requests/responses headers, but in these experiments there was close to nothing in the headers. Consequently, \gls{http}/2 spent some time dealing with compression, while \gls{http}/1 simply sent the request with headers in plain text. This pattern continues throughout Single-\gls{az} and Multi-\gls{az} experiments.

Both \gls{http}/1 and \gls{http}/2 maintained the previous observed pattern when using \gls{tls}. However, latency and throughput got worse due to \gls{tls}â€™ data encryption and \gls{tls} handshake requirements. The latter is better observed in the persistent experiments, while the former is the main reason for the further difference between protocols during ephemeral experiments.

\gls{http}/3 starts with similar results to \gls{http}/2 with \gls{tls}, but starting from 32KiB data size it starts widening the difference between them both. As data size is increased, QUIC only gets worse, further demonstrating it performs poorly on a reliable network when compared with \gls{http}/2 with \gls{tls}. This is similar to the comparison between QUIC and \gls{tcp}+\gls{tls} protocols, since it appears they are the deciding factor when it comes to performance between \gls{http}/2 and \gls{http}/3.

\clearpage

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/charts/Persistent Application-Layer Client Latency (90th Percentile).png}
    \caption{Persistent Application-Layer Client Latency (90th Percentile)}
    \label{fig:persistent_app_latency}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/charts/Ephemeral Application-Layer Client Latency (90th Percentile).png}
    \caption{Ephemeral Application-Layer Client Latency (90th Percentile)}
    \label{fig:ephemeral_app_latency}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/charts/Parallel Persistent Application-Layer Client Latency (90th Percentile).png}
    \caption{Parallel Persistent Application-Layer Client Latency (90th Percentile)}
    \label{fig:parallel_app_latency}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/charts/Persistent Application-Layer Client Throughput in Mb_s (90th Percentile).png}
    \caption{Persistent Application-Layer Client Throughput in Mb/s (90th Percentile)}
    \label{fig:persistent_app_throughput}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/charts/Ephemeral Application-Layer Client Throughput in Mb_s (90th Percentile).png}
    \caption{Ephemeral Application-Layer Client Throughput in Mb/s (90th Percentile)}
    \label{fig:ephemeral_app_throughput}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/charts/Parallel Persistent Application-Layer Client Throughput in Mb_s (90th Percentile).png}
    \caption{Ephemeral Application-Layer Client Throughput in Mb/s (90th Percentile)}
    \label{fig:parallel_app_throughput}
\end{figure}
